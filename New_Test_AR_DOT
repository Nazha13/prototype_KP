# realtime_client_with_custom_keys.py

import requests
import cv2
import os
import re
import threading
import time
from concurrent.futures import ThreadPoolExecutor

class RealTimeARClient:
    """
    A class to manage the real-time AR tracking client.
    This version uses separate inputs for 'object_id' and 'prompt'
    to work with the stateful server API.

    Controls:
    - 'o': Type a new Object ID (what to verify).
    - 'p': Type a new Prompt (the pointing instruction).
    - 's': Sample the frame to run the verify/prompt sequence.
    - 'q': Quit the application.
    """
    def __init__(self, server_url, droidcam_url):
        # --- Configuration ---
        self.server_url = server_url.rstrip('/')
        self.droidcam_url = droidcam_url
        self.object_id = "a blue mug"  # What the server should verify
        self.prompt = "point to the handle" # The pointing instruction
        self.dot_radius = 10
        self.dot_color = (0, 0, 255)

        # --- State Variables ---
        self.trackers = []
        self.tracking_active = False
        self.is_detecting = False
        self.input_mode = None  # Can be 'object_id' or 'prompt'
        self.typed_text = ""
        self.lock = threading.Lock()
        self.executor = ThreadPoolExecutor(max_workers=10)

    def _run_detection_sequence(self, frame, object_id, prompt):
        """
        [Threaded] Handles the two-step API call.
        1. POST to /verify with the object_id.
        2. POST to /prompt with the prompt and the returned image_id.
        """
        print(f"\n[Thread] Starting detection for Object='{object_id}', Prompt='{prompt}'")
        temp_frame_path = "temp_frame_for_detection.jpg"
        cv2.imwrite(temp_frame_path, frame)

        try:
            # --- STEP 1: VERIFY THE OBJECT ---
            print(f"[Thread] Step 1: Verifying '{object_id}'...")
            verify_url = f"{self.server_url}/verify"
            
            with open(temp_frame_path, 'rb') as f:
                files = {'image': (os.path.basename(temp_frame_path), f, 'image/jpeg')}
                payload = {'object_id': object_id}
                response_verify = requests.post(verify_url, files=files, data=payload)

            if response_verify.status_code != 200:
                detail = response_verify.json().get('detail', 'Unknown error')
                print(f"[Thread] Verification FAILED. Server says: {detail}")
                return

            result_verify = response_verify.json()
            image_id = result_verify.get("image_id")

            if not image_id:
                print("[Thread] Verification step did not return an image_id.")
                return

            print(f"[Thread] Verification successful. Received image_id: {image_id}")

            # --- STEP 2: RUN THE PROMPT ---
            print(f"[Thread] Step 2: Running prompt '{prompt}'...")
            prompt_url = f"{self.server_url}/prompt"
            payload_prompt = {'image_id': image_id, 'prompt': prompt}

            response_prompt = requests.post(prompt_url, data=payload_prompt)
            response_prompt.raise_for_status()
            
            result_prompt = response_prompt.json()
            print(f"[Thread] Server Answer: {result_prompt.get('answer')}")

            answer_text = result_prompt.get('answer', '')
            point_pattern = r'\(\s*(\d+)\s*,\s*(\d+)\s*\)'
            extracted_points = re.findall(point_pattern, answer_text)
            
            new_trackers = []
            if extracted_points:
                points = [(int(x), int(y)) for x, y in extracted_points]
                print(f"[Thread] Initial points detected at: {points}")
                for point in points:
                    bbox = (point[0] - 25, point[1] - 25, 50, 50)
                    tracker = cv2.TrackerCSRT_create()
                    tracker.init(frame, bbox)
                    new_trackers.append(tracker)
            else:
                print("[Thread] Pointing complete, but no coordinates found.")

            with self.lock:
                self.trackers = new_trackers
                self.tracking_active = bool(self.trackers)

        except requests.exceptions.RequestException as e:
            print(f"[Thread] Network Error: {e}")
        except Exception as e:
            print(f"[Thread] An unexpected error occurred: {e}")
        finally:
            with self.lock:
                self.is_detecting = False
            if os.path.exists(temp_frame_path):
                os.remove(temp_frame_path)

    def _update_trackers(self, frame):
        """ Updates all active trackers. """
        if not self.trackers:
            self.tracking_active = False
            return

        futures = [self.executor.submit(tracker.update, frame) for tracker in self.trackers]
        updated_trackers = []
        for i, future in enumerate(futures):
            success, bbox = future.result()
            if success:
                updated_trackers.append(self.trackers[i])
                center_x = int(bbox[0] + bbox[2] / 2)
                center_y = int(bbox[1] + bbox[3] / 2)
                cv2.circle(frame, (center_x, center_y), self.dot_radius, self.dot_color, -1)
        
        self.trackers = updated_trackers
        if not self.trackers:
            self.tracking_active = False

    def _draw_hud(self, frame):
        """ Draws the Heads-Up Display. """
        # --- Text Input Mode ---
        if self.input_mode:
            cursor = "|" if int(time.time() * 2) % 2 == 0 else ""
            label = "Object ID" if self.input_mode == 'object_id' else "Prompt"
            prompt_text = f"New {label}: {self.typed_text}{cursor}"
            
            # Draw text with a black outline for better visibility
            text_pos = (20, frame.shape[0] - 55)
            cv2.putText(frame, prompt_text, (text_pos[0] + 2, text_pos[1] + 2), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,0), 3)
            cv2.putText(frame, prompt_text, text_pos, cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
            return

        # --- Normal Mode ---
        y_offset = 40
        def draw_text(text):
            nonlocal y_offset
            cv2.putText(frame, text, (20, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)
            y_offset += 30

        draw_text("Press 's' to sample")
        draw_text("Press 'o' to change Object ID")
        draw_text("Press 'p' to change Prompt")
        draw_text("Press 'q' to quit")

        if self.is_detecting:
            cv2.putText(frame, "Detecting...", (20, y_offset + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 255), 2)

        # Display current object_id and prompt at the bottom
        cv2.putText(frame, f"Object ID: {self.object_id}", (20, frame.shape[0] - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        cv2.putText(frame, f"Prompt: {self.prompt}", (20, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)

    def _handle_key_press(self, key, frame):
        """ Handles all keyboard input. """
        if key == 255: return True

        # --- Handle typing mode ---
        if self.input_mode:
            if key == 13: # Enter
                with self.lock:
                    if self.input_mode == 'object_id':
                        self.object_id = self.typed_text
                        print(f"Object ID set to: '{self.object_id}'")
                    elif self.input_mode == 'prompt':
                        self.prompt = self.typed_text
                        print(f"Prompt set to: '{self.prompt}'")
                    self.input_mode = None
                    self.typed_text = ""
            elif key == 8: # Backspace
                self.typed_text = self.typed_text[:-1]
            elif 32 <= key <= 126: # Printable characters
                self.typed_text += chr(key)
            return True

        # --- Handle normal mode keys ---
        if key == ord('q'): return False
        
        if key == ord('s'):
            with self.lock:
                if self.is_detecting: return True
                self.tracking_active = False
                self.is_detecting = True
                self.trackers = []
            threading.Thread(target=self._run_detection_sequence, args=(frame.copy(), self.object_id, self.prompt)).start()
        
        elif key == ord('o'):
            self.input_mode = 'object_id'
            self.typed_text = self.object_id
        
        elif key == ord('p'):
            self.input_mode = 'prompt'
            self.typed_text = self.prompt
        
        return True

    def run(self):
        """ Main application loop. """
        print("Starting client...")
        cap = cv2.VideoCapture(self.droidcam_url)
        if not cap.isOpened():
            print(f"Error: Could not open stream at {self.droidcam_url}")
            return

        cv2.namedWindow("AR Client")
        while True:
            ret, frame = cap.read()
            if not ret: break

            if self.tracking_active:
                self._update_trackers(frame)

            self._draw_hud(frame)
            cv2.imshow("AR Client", frame)
            
            key = cv2.waitKey(1) & 0xFF
            if not self._handle_key_press(key, frame):
                break

        self.executor.shutdown()
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    SERVER_URL = "https://balanced-vaguely-mastodon.ngrok-free.app"
    DROIDCAM_URL = "http://192.168.133.7:4747/video"
    
    client = RealTimeARClient(SERVER_URL, DROIDCAM_URL)
    client.run()